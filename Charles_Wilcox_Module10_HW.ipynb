{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CQTHkOAuJOc"
      },
      "source": [
        "## Homework Week 10\n",
        "\n",
        "1. Explain the idea of bag-of-words model.\n",
        "\n",
        "2. What are the two methods to treat the meaningless frequently occurring words?\n",
        "\n",
        "3. Classify the documents in fetch_20newsgroups.\n",
        "\n",
        "```python\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.model_selection import train_test_split\n",
        "categories = ['alt.atheism', 'soc.religion.christian',\n",
        "              'comp.graphics', 'sci.med']\n",
        "\n",
        "news = fetch_20newsgroups(categories=categories, shuffle=True, random_state=1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(news.data, news.target, test_size = 0.5, random_state=1)\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8UllHlH4INP"
      },
      "source": [
        "**Problem 1: Explain the idea of bag-of-words model.**\n",
        "\n",
        "\\\n",
        "The bag-of-words model can be summarized in two steps:\n",
        "\n",
        "First, create a vocabulary of unique tokens such as words from an entire set of documents. This is a list of all the unique words that appear in all of the documents.\n",
        "\n",
        "Then, create feature vectors from each document that contain counts of how often each word occurs in the document. \n",
        "\n",
        "Each feature vector will include a lot of zeros since each document contains only a small subset of all the words. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XYWjl4WJxkL"
      },
      "source": [
        "**Problem 2: What are the two methods to treat the meaningless frequently occurring words?**\n",
        "\n",
        "\\\n",
        "1. **term frequency-inverse document frequency (tf-idf)** - tf-idf can be used to downweight frequently occurring words in the feature vectors. tf-idf is the product of the term frequency and the inverse document frequency. Scikit-learn has a transformer called TfidfTransformer that can be used with CountVectorizer to assign tf-idfs to raw term frequencies in the bag-of-words model.\n",
        "\n",
        "\n",
        "2. **stop-words removal** - stop-words are a set of common words that show up in text that have little or no meaning. These are words like is, the, has, etc. Because stop-words contain little to no actual meaning, they can be removed. The Natural Language Toolkit (NLKT) library provides a set of 127 English stop-words that can be used to remove stop-words from the bag-of-words model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zdiO1k5RDrT"
      },
      "source": [
        "**Problem 3: Classify the documents in fetch_20newsgroups.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "c-9X7Fh3uJOf"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.model_selection import train_test_split\n",
        "categories = ['alt.atheism', 'soc.religion.christian',\n",
        "              'comp.graphics', 'sci.med']\n",
        " \n",
        "news = fetch_20newsgroups(categories=categories, shuffle=True, random_state=1)\n",
        " \n",
        "X_train, X_test, y_train, y_test = train_test_split(news.data, news.target, test_size = 0.5, random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jed8padDHIUT",
        "outputId": "c5025fff-fd0f-417b-8d5b-6ff2cb3f429e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "count = CountVectorizer()\n",
        "tfidf = TfidfTransformer()\n",
        "porter = PorterStemmer() \n",
        "stop = stopwords.words('english')\n",
        "\n",
        "def preprocessor(text):\n",
        "    text = re.sub('<[^>]*>', '', text)\n",
        "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)',\n",
        "                           text)\n",
        "    text = (re.sub('[\\W]+', ' ', text.lower()) +\n",
        "            ' '.join(emoticons).replace('-', ''))\n",
        "    return text\n",
        "\n",
        "def tokenizer(text):\n",
        "    return text.split()\n",
        "   \n",
        "def tokenizer_porter(text):\n",
        "    return [porter.stem(word) for word in text.split()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThZX4V4NXNRK",
        "outputId": "86f8de7b-45c6-467e-c440-c6d19eff6348"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/feature_extraction/text.py:396: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'formerli', 'forti', 'ha', 'henc', 'hereaft', 'herebi', 'hi', 'howev', 'hundr', 'inde', 'latterli', 'mani', 'meanwhil', 'moreov', 'mostli', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'seriou', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'thi', 'thu', 'togeth', 'twelv', 'twenti', 'veri', 'wa', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5,\n",
              "             estimator=Pipeline(steps=[('vect',\n",
              "                                        TfidfVectorizer(lowercase=False,\n",
              "                                                        stop_words='english')),\n",
              "                                       ('clf',\n",
              "                                        LogisticRegression(random_state=0,\n",
              "                                                           solver='liblinear'))]),\n",
              "             n_jobs=-1,\n",
              "             param_grid=[{'clf__penalty': ['l1', 'l2'],\n",
              "                          'vect__tokenizer': [<function tokenizer at 0x7fd9bc43d1f0>,\n",
              "                                              <function tokenizer_porter at 0x7fd9bc43d550>]}],\n",
              "             scoring='accuracy', verbose=1)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tfidf = TfidfVectorizer(strip_accents=None,\n",
        "                        lowercase=False,\n",
        "                        preprocessor=None,\n",
        "                        stop_words='english'\n",
        "                        )\n",
        "\n",
        "param_grid = [{\n",
        "               'vect__tokenizer': [tokenizer, tokenizer_porter],\n",
        "               'clf__penalty': ['l1', 'l2']},\n",
        "              ]\n",
        "\n",
        "lr_tfidf = Pipeline([('vect', tfidf),\n",
        "                     ('clf', LogisticRegression(random_state=0, solver='liblinear'))])\n",
        "\n",
        "gs_lr_tfidf = GridSearchCV(lr_tfidf, \n",
        "                           param_grid,\n",
        "                           scoring='accuracy',\n",
        "                           cv=5,\n",
        "                           verbose=1,\n",
        "                           n_jobs=-1)\n",
        "\n",
        "gs_lr_tfidf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vr0Vb9AOQKW1",
        "outputId": "2b01e1ba-69a1-4466-a562-a49448c026df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best parameter set: {'clf__penalty': 'l2', 'vect__tokenizer': <function tokenizer_porter at 0x7fd9bc43d550>} \n",
            "CV Accuracy: 0.910\n"
          ]
        }
      ],
      "source": [
        "print('Best parameter set: %s ' % gs_lr_tfidf.best_params_)\n",
        "print('CV Accuracy: %.3f' % gs_lr_tfidf.best_score_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ll_edpuhQhTv",
        "outputId": "ecfb6319-c022-4d5c-8961-c7a0a7547b14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.919\n"
          ]
        }
      ],
      "source": [
        "clf = gs_lr_tfidf.best_estimator_\n",
        "print('Test Accuracy: %.3f' % clf.score(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "rrzLK5txRTDK",
        "outputId": "ac733856-6151-4494-95a2-3621f3eebf03"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5ffd11e2-9229-48c3-8d01-8e2341bd6997\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Documents</th>\n",
              "      <th>Class Predictions</th>\n",
              "      <th>Actual Class Values</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>From: wjhovi01@ulkyvx.louisville.edu\\nSubject:...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>From: zyeh@caspian.usc.edu (zhenghao yeh)\\nSub...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>From: newmme@helios.tn.cornell.edu (Mark E. J....</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>From: peterbak@microsoft.com (Peter Bako)\\nSub...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>From: euclid@mrcnext.cso.uiuc.edu (Euclid K.)\\...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>From: joachim@kih.no (joachim lous)\\nSubject: ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>From: boylan@pi.eai.iastate.edu (Terran Boylan...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>From: stgprao@st.unocal.COM (Richard Ottolini)...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>From: mayne@ds3.scri.fsu.edu (Bill Mayne)\\nSub...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>From: mrb@cbnewsj.cb.att.com (m..bruncati)\\nSu...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>From: ab961@Freenet.carleton.ca (Robert Alliso...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>From: jodfishe@silver.ucs.indiana.edu (joseph ...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>From: aidler@sol.uvic.ca (E Alan Idler)\\nSubje...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>From: lm001@rrz.Uni-Koeln.DE (Erwin H. Keeve)\\...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>From: jhpb@sarto.budd-lake.nj.us (Joseph H. Bu...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>From: thinman@netcom.com (Technically Sweet)\\n...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>From: jfare@53iss6.Waterloo.NCR.COM (Jim Fare)...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>From: smayo@world.std.com (Scott A Mayo)\\nSubj...</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>From: I3150101@dbstu1.rz.tu-bs.de (Benedikt Ro...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>From: noring@netcom.com (Jon Noring)\\nSubject:...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5ffd11e2-9229-48c3-8d01-8e2341bd6997')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5ffd11e2-9229-48c3-8d01-8e2341bd6997 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5ffd11e2-9229-48c3-8d01-8e2341bd6997');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                            Documents  Class Predictions  \\\n",
              "0   From: wjhovi01@ulkyvx.louisville.edu\\nSubject:...                  3   \n",
              "1   From: zyeh@caspian.usc.edu (zhenghao yeh)\\nSub...                  1   \n",
              "2   From: newmme@helios.tn.cornell.edu (Mark E. J....                  1   \n",
              "3   From: peterbak@microsoft.com (Peter Bako)\\nSub...                  1   \n",
              "4   From: euclid@mrcnext.cso.uiuc.edu (Euclid K.)\\...                  2   \n",
              "5   From: joachim@kih.no (joachim lous)\\nSubject: ...                  1   \n",
              "6   From: boylan@pi.eai.iastate.edu (Terran Boylan...                  1   \n",
              "7   From: stgprao@st.unocal.COM (Richard Ottolini)...                  2   \n",
              "8   From: mayne@ds3.scri.fsu.edu (Bill Mayne)\\nSub...                  3   \n",
              "9   From: mrb@cbnewsj.cb.att.com (m..bruncati)\\nSu...                  2   \n",
              "10  From: ab961@Freenet.carleton.ca (Robert Alliso...                  2   \n",
              "11  From: jodfishe@silver.ucs.indiana.edu (joseph ...                  3   \n",
              "12  From: aidler@sol.uvic.ca (E Alan Idler)\\nSubje...                  3   \n",
              "13  From: lm001@rrz.Uni-Koeln.DE (Erwin H. Keeve)\\...                  1   \n",
              "14  From: jhpb@sarto.budd-lake.nj.us (Joseph H. Bu...                  3   \n",
              "15  From: thinman@netcom.com (Technically Sweet)\\n...                  1   \n",
              "16  From: jfare@53iss6.Waterloo.NCR.COM (Jim Fare)...                  2   \n",
              "17  From: smayo@world.std.com (Scott A Mayo)\\nSubj...                  3   \n",
              "18  From: I3150101@dbstu1.rz.tu-bs.de (Benedikt Ro...                  0   \n",
              "19  From: noring@netcom.com (Jon Noring)\\nSubject:...                  2   \n",
              "\n",
              "    Actual Class Values  \n",
              "0                     3  \n",
              "1                     1  \n",
              "2                     1  \n",
              "3                     1  \n",
              "4                     2  \n",
              "5                     1  \n",
              "6                     1  \n",
              "7                     2  \n",
              "8                     3  \n",
              "9                     2  \n",
              "10                    2  \n",
              "11                    3  \n",
              "12                    3  \n",
              "13                    1  \n",
              "14                    3  \n",
              "15                    1  \n",
              "16                    2  \n",
              "17                    3  \n",
              "18                    0  \n",
              "19                    2  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "predict = gs_lr_tfidf.predict(X_test)\n",
        "\n",
        "data = {'Documents':X_test, 'Class Predictions':predict, 'Actual Class Values':y_test}\n",
        "\n",
        "predictions = pd.DataFrame(data)\n",
        "predictions.head(20)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
