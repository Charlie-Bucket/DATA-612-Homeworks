{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ue2UOqaBuuEL"
   },
   "source": [
    "## Homework Week 11\n",
    "\n",
    "1. Why is it generally preferable to use a Logistic Regression classifier rather than a classical Perceptron (i.e., a single layer of threshold logic units trained using the Perceptron training algorithm)? How can you tweak a Perceptron to make it equivalent to a Logistic Regression classifier?\n",
    "\n",
    "2. Can you list all the hyperparameters you can tweak in a basic MLP? If the MLP overfits the training data, how could you tweak these hyperparameters to try to solve the problem?\n",
    "\n",
    "3. Train a deep MLP on the MNIST dataset (you can load it using keras.datasets.mnist.load_data(). See what accuracy you can get. Try searching for the optimal learning rate. The MNIST dataset is a set of 70,000 small images of digits handwritten (0-9) by high school students and employees of the US Census Bureau. Each image is labeled with the digit it represents. There are 70,000 images, and each image has 784 features. This is because each image is 28 × 28 pixels, and each feature simply represents one pixel’s intensity, from 0 (white) to 255 (black).\n",
    "\n",
    "To check the out of sample accuracy: \n",
    "```\n",
    "model.evaluate(X_test, y_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CxlKnCeKvu4g"
   },
   "source": [
    "**Problem 1: Why is it generally preferable to use a Logistic Regression classifier rather than a classical Perceptron (i.e., a single layer of threshold logic units trained using the Perceptron training algorithm)? How can you tweak a Perceptron to make it equivalent to a Logistic Regression classifier?**\n",
    "\n",
    "A classical Perceptron and Logistic Regression are both classifiers that can be used to predict binary variables and set decision boundries. Logistic Regression uses probability to classify the target in a range between 0 and 1. A classical Perceptron (single-layer perceptron) uses examples and weights to classify values either -1 or 1. Perceptrons take inputs of feature vectors and multiplies them with the weight vector to compute the net input and makes classifications. In the case of a misclassification, the weight is updated and the net input recalculated. This repetition (sometimes 10s of thousands iterations) makes perceptrons time-consuming, when a decision boundry can be easily found with a logistic regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jot3CLag2dcq"
   },
   "source": [
    "**Problem 2.1: Can you list all the hyperparameters you can tweak in a basic MLP?**\n",
    "\n",
    "The Scikit-Learn MLP Classifier has the following hyperparameters: hidden_layer_sizes, activation, solver, alpha, batch_size, learning_rate, learning_rate_init, power_t, max_iter, shuffle, random_state, tol, verbose, warm_start, momentum, nesterovs_momentum, early_stopping, validation_fraction, beta_1, beta_2, epsilon, n_iter_no_change, max_fun."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pXk5GZRp7HmT"
   },
   "source": [
    "**Problem 2.2: If the MLP overfits the training data, how could you tweak these hyperparameters to try to solve the problem?**\n",
    "\n",
    "Early_stopping can be set to True and training will be terminated when the validation score is not improving.\n",
    "\n",
    "Or, a tolerance (tol) can be set to terminate the training when the loss or score is not improving by at least tol for n_iter_no_change (the maximum number of epochs to not see tol improvement).\n",
    "\n",
    "Or, learning_rate can be set to adaptive which keeps the learning rate constant to ‘learning_rate_init’ as long as training loss keeps decreasing. Each time two consecutive epochs fail to decrease training loss by at least tol, or fail to increase validation score by at least tol if ‘early_stopping’ is on, the current learning rate is divided by 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FffnWFZ496zb"
   },
   "source": [
    "**Problem 3: Train a deep MLP on the MNIST dataset (you can load it using keras.datasets.mnist.load_data(). See what accuracy you can get. Try searching for the optimal learning rate. The MNIST dataset is a set of 70,000 small images of digits handwritten (0-9) by high school students and employees of the US Census Bureau. Each image is labeled with the digit it represents. There are 70,000 images, and each image has 784 features. This is because each image is 28 × 28 pixels, and each feature simply represents one pixel’s intensity, from 0 (white) to 255 (black).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RKYsGRGIuuEO"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "print(\"X_train Shape:\", X_train.shape)\n",
    "print(\"y_train Values:\", np.unique(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dztJgQegByJl"
   },
   "source": [
    "###Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DowrPSFB_b5z",
    "outputId": "55339a87-e223-46ae-c29f-5f6f258da638"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(60000, 10), dtype=float32, numpy=\n",
       "array([[0.16092604, 0.03965664, 0.10473278, ..., 0.15350746, 0.11682192,\n",
       "        0.03146256],\n",
       "       [0.157025  , 0.03209527, 0.08726551, ..., 0.19488981, 0.10402052,\n",
       "        0.02806727],\n",
       "       [0.15760276, 0.03533459, 0.09258626, ..., 0.15044665, 0.12086402,\n",
       "        0.03088022],\n",
       "       ...,\n",
       "       [0.18974268, 0.03885382, 0.08273212, ..., 0.16255164, 0.11853555,\n",
       "        0.02578707],\n",
       "       [0.16280916, 0.03785788, 0.09159419, ..., 0.1993969 , 0.12086872,\n",
       "        0.02389017],\n",
       "       [0.16832487, 0.03797522, 0.09618536, ..., 0.13419726, 0.11291031,\n",
       "        0.02952256]], dtype=float32)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model1 creation\n",
    "\n",
    "model1 = keras.models.Sequential() #keras model\n",
    "\n",
    "model1.add(keras.layers.Flatten(input_shape=[28, 28])) #input layer\n",
    "\n",
    "#hidden layers\n",
    "model1.add(keras.layers.Dense(100, activation='sigmoid'))\n",
    "model1.add(keras.layers.Dense(50, activation='sigmoid'))\n",
    "\n",
    "model1.add(keras.layers.Dense(len(np.unique(y_train)), activation='softmax')) #output layer\n",
    "\n",
    "model1(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iW68X5vBB4Iv"
   },
   "outputs": [],
   "source": [
    "#compile the model\n",
    "\n",
    "model1.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5RZTcucbEigj",
    "outputId": "4f337c97-c48e-4829-e6e2-f6ecacd24d2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.4227 - accuracy: 0.7179 - val_loss: 0.8231 - val_accuracy: 0.8631\n",
      "Epoch 2/50\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.6282 - accuracy: 0.8758 - val_loss: 0.4846 - val_accuracy: 0.8966\n",
      "Epoch 3/50\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.4419 - accuracy: 0.8963 - val_loss: 0.3809 - val_accuracy: 0.9080\n",
      "Epoch 4/50\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3681 - accuracy: 0.9082 - val_loss: 0.3395 - val_accuracy: 0.9124\n",
      "Epoch 5/50\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3329 - accuracy: 0.9141 - val_loss: 0.3186 - val_accuracy: 0.9156\n",
      "Epoch 6/50\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3117 - accuracy: 0.9176 - val_loss: 0.2954 - val_accuracy: 0.9214\n",
      "Epoch 7/50\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2914 - accuracy: 0.9217 - val_loss: 0.2936 - val_accuracy: 0.9225\n",
      "Epoch 8/50\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2783 - accuracy: 0.9243 - val_loss: 0.2743 - val_accuracy: 0.9250\n",
      "Epoch 9/50\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2630 - accuracy: 0.9278 - val_loss: 0.2633 - val_accuracy: 0.9266\n",
      "Epoch 10/50\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2537 - accuracy: 0.9292 - val_loss: 0.2470 - val_accuracy: 0.9319\n",
      "Epoch 11/50\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2452 - accuracy: 0.9323 - val_loss: 0.2438 - val_accuracy: 0.9302\n",
      "Epoch 12/50\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2429 - accuracy: 0.9312 - val_loss: 0.2401 - val_accuracy: 0.9318\n",
      "Epoch 13/50\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2382 - accuracy: 0.9329 - val_loss: 0.2365 - val_accuracy: 0.9339\n",
      "Epoch 14/50\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2309 - accuracy: 0.9356 - val_loss: 0.2223 - val_accuracy: 0.9385\n",
      "Epoch 15/50\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2254 - accuracy: 0.9352 - val_loss: 0.2196 - val_accuracy: 0.9378\n",
      "Epoch 16/50\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2187 - accuracy: 0.9369 - val_loss: 0.2173 - val_accuracy: 0.9384\n",
      "Epoch 17/50\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2085 - accuracy: 0.9393 - val_loss: 0.2092 - val_accuracy: 0.9410\n",
      "Epoch 18/50\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.2115 - accuracy: 0.9390 - val_loss: 0.2166 - val_accuracy: 0.9383\n"
     ]
    }
   ],
   "source": [
    "#set early stopping and fit the model\n",
    "\n",
    "callback1 = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=1) #terminates when number of epochs with no improvement = 1\n",
    "\n",
    "history1 = model1.fit(X_train, y_train, \n",
    "                    epochs=50,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    callbacks=[callback1]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oh61PNm6HMmi",
    "outputId": "dd9d3b5e-ec8a-4766-af38-b3f3d4e4bd20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2166 - accuracy: 0.9383\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.21664279699325562, 0.9383000135421753]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "id": "pAJAovdnLL_Z",
    "outputId": "c28ac7d5-9adf-4c1a-b81b-320f5785652d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        loss  accuracy  val_loss  val_accuracy\n",
      "0   1.422688  0.717850  0.823118        0.8631\n",
      "1   0.628217  0.875767  0.484564        0.8966\n",
      "2   0.441926  0.896333  0.380888        0.9080\n",
      "3   0.368140  0.908167  0.339493        0.9124\n",
      "4   0.332937  0.914083  0.318604        0.9156\n",
      "5   0.311727  0.917583  0.295439        0.9214\n",
      "6   0.291382  0.921717  0.293560        0.9225\n",
      "7   0.278281  0.924283  0.274291        0.9250\n",
      "8   0.263019  0.927800  0.263322        0.9266\n",
      "9   0.253725  0.929233  0.246961        0.9319\n",
      "10  0.245174  0.932300  0.243795        0.9302\n",
      "11  0.242945  0.931150  0.240088        0.9318\n",
      "12  0.238239  0.932933  0.236451        0.9339\n",
      "13  0.230857  0.935617  0.222337        0.9385\n",
      "14  0.225408  0.935250  0.219618        0.9378\n",
      "15  0.218744  0.936867  0.217263        0.9384\n",
      "16  0.208468  0.939283  0.209158        0.9410\n",
      "17  0.211508  0.939017  0.216643        0.9383\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f2726bc6490>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#create dataframe containing the metrics measured at the end of each epoch on the training and validation sets\n",
    "df = pd.DataFrame(history1.history)\n",
    "print(df)\n",
    "\n",
    "# plot the scores\n",
    "df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p8UdcgXiB3x0"
   },
   "source": [
    "###Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "osg7rwrI8dCK",
    "outputId": "093c42b8-6adb-4527-c16a-cbccdd73b1b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(60000, 10), dtype=float32, numpy=\n",
       "array([[0.08026844, 0.08804706, 0.32702228, ..., 0.0620256 , 0.06883678,\n",
       "        0.03947371],\n",
       "       [0.0743455 , 0.07951791, 0.3290584 , ..., 0.06492935, 0.07290133,\n",
       "        0.0395142 ],\n",
       "       [0.06648637, 0.07761257, 0.34128654, ..., 0.05593676, 0.05901832,\n",
       "        0.038095  ],\n",
       "       ...,\n",
       "       [0.08869168, 0.08088581, 0.31007603, ..., 0.06447735, 0.0722542 ,\n",
       "        0.04176708],\n",
       "       [0.06403504, 0.07395824, 0.3267385 , ..., 0.07739171, 0.06778841,\n",
       "        0.03920728],\n",
       "       [0.07927562, 0.08644482, 0.32599786, ..., 0.05212037, 0.06160862,\n",
       "        0.04088774]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model2 creation\n",
    "\n",
    "model2 = keras.models.Sequential() #keras model\n",
    "\n",
    "model2.add(keras.layers.Flatten(input_shape=[28, 28])) #input layer\n",
    "\n",
    "#hidden layers - default activation function is ReLU\n",
    "model2.add(keras.layers.Dense(50, activation='sigmoid'))\n",
    "model2.add(keras.layers.Dense(10, activation='sigmoid'))\n",
    "\n",
    "model2.add(keras.layers.Dense(len(np.unique(y_train)), activation='softmax')) #output layer\n",
    "\n",
    "model2(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uZ7A4JTFBo2F"
   },
   "outputs": [],
   "source": [
    "#compile model2\n",
    "\n",
    "model2.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iyXsirXB8cXM",
    "outputId": "f50212aa-fd57-4bd3-d610-74389a538cc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 1.9051 - accuracy: 0.4629 - val_loss: 1.5424 - val_accuracy: 0.6311\n",
      "Epoch 2/50\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 1.2950 - accuracy: 0.7175 - val_loss: 1.0830 - val_accuracy: 0.7971\n",
      "Epoch 3/50\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.9450 - accuracy: 0.8213 - val_loss: 0.8118 - val_accuracy: 0.8551\n",
      "Epoch 4/50\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.7396 - accuracy: 0.8586 - val_loss: 0.6831 - val_accuracy: 0.8673\n",
      "Epoch 5/50\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.6190 - accuracy: 0.8733 - val_loss: 0.5544 - val_accuracy: 0.8885\n",
      "Epoch 6/50\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5441 - accuracy: 0.8812 - val_loss: 0.5343 - val_accuracy: 0.8767\n",
      "Epoch 7/50\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5096 - accuracy: 0.8824 - val_loss: 0.4845 - val_accuracy: 0.8898\n",
      "Epoch 8/50\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4648 - accuracy: 0.8896 - val_loss: 0.4684 - val_accuracy: 0.8860\n",
      "Epoch 9/50\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4418 - accuracy: 0.8942 - val_loss: 0.3989 - val_accuracy: 0.9009\n",
      "Epoch 10/50\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4126 - accuracy: 0.8958 - val_loss: 0.3961 - val_accuracy: 0.9001\n",
      "Epoch 11/50\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3962 - accuracy: 0.9008 - val_loss: 0.3876 - val_accuracy: 0.9014\n",
      "Epoch 12/50\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3838 - accuracy: 0.9014 - val_loss: 0.3898 - val_accuracy: 0.8990\n",
      "Epoch 13/50\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3779 - accuracy: 0.9012 - val_loss: 0.3702 - val_accuracy: 0.9003\n",
      "Epoch 14/50\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3636 - accuracy: 0.9036 - val_loss: 0.3665 - val_accuracy: 0.9023\n",
      "Epoch 15/50\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3500 - accuracy: 0.9083 - val_loss: 0.3456 - val_accuracy: 0.9073\n",
      "Epoch 16/50\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3370 - accuracy: 0.9116 - val_loss: 0.3545 - val_accuracy: 0.9021\n",
      "Epoch 17/50\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3421 - accuracy: 0.9072 - val_loss: 0.3267 - val_accuracy: 0.9111\n"
     ]
    }
   ],
   "source": [
    "#set early stopping and fit the model\n",
    "\n",
    "callback2 = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=1) #terminate if number of epochs with no improvement = 3\n",
    "\n",
    "history2 = model2.fit(X_train, y_train, \n",
    "                    epochs=50,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    callbacks=[callback2]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 595
    },
    "id": "GCIbRO8eBR16",
    "outputId": "d33ed5ed-3569-4b9a-e7cc-f29d90c7077c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        loss  accuracy  val_loss  val_accuracy\n",
      "0   1.905074  0.462933  1.542416        0.6311\n",
      "1   1.294981  0.717483  1.082992        0.7971\n",
      "2   0.944957  0.821250  0.811824        0.8551\n",
      "3   0.739608  0.858633  0.683057        0.8673\n",
      "4   0.619007  0.873267  0.554381        0.8885\n",
      "5   0.544121  0.881200  0.534323        0.8767\n",
      "6   0.509604  0.882400  0.484501        0.8898\n",
      "7   0.464828  0.889567  0.468434        0.8860\n",
      "8   0.441789  0.894183  0.398880        0.9009\n",
      "9   0.412552  0.895800  0.396116        0.9001\n",
      "10  0.396185  0.900783  0.387595        0.9014\n",
      "11  0.383787  0.901417  0.389805        0.8990\n",
      "12  0.377901  0.901167  0.370242        0.9003\n",
      "13  0.363595  0.903600  0.366529        0.9023\n",
      "14  0.350012  0.908333  0.345568        0.9073\n",
      "15  0.336990  0.911617  0.354460        0.9021\n",
      "16  0.342064  0.907233  0.326740        0.9111\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f2728b24670>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#create dataframe containing the metrics measured at the end of each epoch on the training and validation sets\n",
    "df = pd.DataFrame(history2.history)\n",
    "print(df)\n",
    "\n",
    "# plot the scores\n",
    "df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TuSN_etzNCYV"
   },
   "source": [
    "**See what accuracy you can get.**\n",
    "\n",
    "I originally set the layers at 300 and 100, the epochs at 50, and the EarlyStopping at monitor='loss' and patience of 3. The model ran for 37 epochs, took a long time, but resulted in a 96% accuracy. Because it took so long to run, I changed the hidden layer density to 100 and 50, and then to 50 and 10. I got an accuracy of 94% and 91%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iAjwAevrXnG-",
    "outputId": "4a2356db-8b82-4f99-b889-c0c765b16463"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'optimizer': <keras.optimizers.optimizer_v2.gradient_descent.SGD object at 0x7f271d995100>}\n",
      "Training...\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-36-fc98d2d42f7a>:22: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  cls = KerasClassifier(build_fn=make_model)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 7s 3ms/step - loss: 2.3031 - accuracy: 0.0722 - val_loss: 2.3007 - val_accuracy: 0.0897\n",
      "Epoch 2/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 2.2985 - accuracy: 0.1182 - val_loss: 2.2961 - val_accuracy: 0.1310\n",
      "Epoch 3/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2940 - accuracy: 0.1370 - val_loss: 2.2916 - val_accuracy: 0.1276\n",
      "Epoch 4/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2895 - accuracy: 0.1322 - val_loss: 2.2871 - val_accuracy: 0.1354\n",
      "Epoch 5/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2850 - accuracy: 0.1452 - val_loss: 2.2824 - val_accuracy: 0.1490\n",
      "Epoch 6/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 2.2801 - accuracy: 0.1578 - val_loss: 2.2773 - val_accuracy: 0.1642\n",
      "Epoch 7/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2747 - accuracy: 0.1749 - val_loss: 2.2715 - val_accuracy: 0.1796\n",
      "Epoch 8/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2684 - accuracy: 0.1825 - val_loss: 2.2647 - val_accuracy: 0.1875\n",
      "Epoch 9/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 2.2610 - accuracy: 0.1906 - val_loss: 2.2565 - val_accuracy: 0.1911\n",
      "Epoch 10/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2522 - accuracy: 0.1923 - val_loss: 2.2468 - val_accuracy: 0.1938\n",
      "Epoch 11/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 2.2417 - accuracy: 0.1948 - val_loss: 2.2352 - val_accuracy: 0.1947\n",
      "Epoch 12/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2291 - accuracy: 0.2074 - val_loss: 2.2217 - val_accuracy: 0.2197\n",
      "Epoch 13/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2147 - accuracy: 0.2150 - val_loss: 2.2062 - val_accuracy: 0.2139\n",
      "Epoch 14/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 2.1986 - accuracy: 0.2144 - val_loss: 2.1892 - val_accuracy: 0.2185\n",
      "Epoch 15/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.1811 - accuracy: 0.2261 - val_loss: 2.1708 - val_accuracy: 0.2285\n",
      "Epoch 16/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.1623 - accuracy: 0.2414 - val_loss: 2.1510 - val_accuracy: 0.2476\n",
      "Epoch 17/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.1420 - accuracy: 0.2633 - val_loss: 2.1298 - val_accuracy: 0.2741\n",
      "Epoch 18/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 2.1203 - accuracy: 0.2825 - val_loss: 2.1072 - val_accuracy: 0.2899\n",
      "Epoch 19/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 2.0971 - accuracy: 0.2942 - val_loss: 2.0831 - val_accuracy: 0.2989\n",
      "Epoch 20/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.0725 - accuracy: 0.3003 - val_loss: 2.0577 - val_accuracy: 0.3021\n",
      "Epoch 21/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 2.0468 - accuracy: 0.3035 - val_loss: 2.0315 - val_accuracy: 0.3048\n",
      "Epoch 22/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 2.0202 - accuracy: 0.3056 - val_loss: 2.0040 - val_accuracy: 0.3043\n",
      "Epoch 23/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.9926 - accuracy: 0.3061 - val_loss: 1.9763 - val_accuracy: 0.3049\n",
      "Epoch 24/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 1.9647 - accuracy: 0.3067 - val_loss: 1.9484 - val_accuracy: 0.3055\n",
      "Epoch 25/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.9365 - accuracy: 0.3077 - val_loss: 1.9205 - val_accuracy: 0.3062\n",
      "Epoch 26/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 1.9091 - accuracy: 0.3087 - val_loss: 1.8939 - val_accuracy: 0.3076\n",
      "Epoch 27/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 1.8829 - accuracy: 0.3093 - val_loss: 1.8683 - val_accuracy: 0.3079\n",
      "Epoch 28/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.8580 - accuracy: 0.3105 - val_loss: 1.8442 - val_accuracy: 0.3097\n",
      "Epoch 29/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.8348 - accuracy: 0.3122 - val_loss: 1.8219 - val_accuracy: 0.3127\n",
      "Epoch 30/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.8134 - accuracy: 0.3131 - val_loss: 1.8011 - val_accuracy: 0.3141\n",
      "Epoch 31/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.7932 - accuracy: 0.3153 - val_loss: 1.7819 - val_accuracy: 0.3166\n",
      "Epoch 32/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.7745 - accuracy: 0.3169 - val_loss: 1.7644 - val_accuracy: 0.3179\n",
      "Epoch 33/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.7569 - accuracy: 0.3183 - val_loss: 1.7469 - val_accuracy: 0.3192\n",
      "Epoch 34/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.7407 - accuracy: 0.3204 - val_loss: 1.7316 - val_accuracy: 0.3215\n",
      "Epoch 35/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.7255 - accuracy: 0.3224 - val_loss: 1.7172 - val_accuracy: 0.3224\n",
      "Epoch 36/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.7109 - accuracy: 0.3251 - val_loss: 1.7033 - val_accuracy: 0.3258\n",
      "Epoch 37/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.6974 - accuracy: 0.3272 - val_loss: 1.6906 - val_accuracy: 0.3265\n",
      "Epoch 38/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.6850 - accuracy: 0.3286 - val_loss: 1.6781 - val_accuracy: 0.3292\n",
      "Epoch 39/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.6727 - accuracy: 0.3295 - val_loss: 1.6668 - val_accuracy: 0.3314\n",
      "Epoch 40/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.6612 - accuracy: 0.3322 - val_loss: 1.6557 - val_accuracy: 0.3318\n",
      "Epoch 41/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.6501 - accuracy: 0.3349 - val_loss: 1.6454 - val_accuracy: 0.3355\n",
      "Epoch 42/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.6400 - accuracy: 0.3371 - val_loss: 1.6356 - val_accuracy: 0.3353\n",
      "Epoch 43/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.6300 - accuracy: 0.3385 - val_loss: 1.6272 - val_accuracy: 0.3355\n",
      "Epoch 44/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.6206 - accuracy: 0.3399 - val_loss: 1.6183 - val_accuracy: 0.3398\n",
      "Epoch 45/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.6117 - accuracy: 0.3413 - val_loss: 1.6086 - val_accuracy: 0.3410\n",
      "Epoch 46/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.6033 - accuracy: 0.3424 - val_loss: 1.6010 - val_accuracy: 0.3420\n",
      "Epoch 47/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.5950 - accuracy: 0.3434 - val_loss: 1.5931 - val_accuracy: 0.3441\n",
      "Epoch 48/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.5871 - accuracy: 0.3455 - val_loss: 1.5854 - val_accuracy: 0.3473\n",
      "Epoch 49/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 1.5803 - accuracy: 0.3479 - val_loss: 1.5791 - val_accuracy: 0.3463\n",
      "Epoch 50/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.5734 - accuracy: 0.3486 - val_loss: 1.5725 - val_accuracy: 0.3488\n",
      "Epoch 51/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.5664 - accuracy: 0.3527 - val_loss: 1.5661 - val_accuracy: 0.3507\n",
      "Epoch 52/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.5596 - accuracy: 0.3540 - val_loss: 1.5596 - val_accuracy: 0.3522\n",
      "Epoch 53/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.5536 - accuracy: 0.3548 - val_loss: 1.5542 - val_accuracy: 0.3529\n",
      "Epoch 54/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.5478 - accuracy: 0.3583 - val_loss: 1.5488 - val_accuracy: 0.3528\n",
      "Epoch 55/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.5420 - accuracy: 0.3575 - val_loss: 1.5441 - val_accuracy: 0.3547\n",
      "Epoch 56/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.5363 - accuracy: 0.3612 - val_loss: 1.5388 - val_accuracy: 0.3558\n",
      "Epoch 57/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.5309 - accuracy: 0.3611 - val_loss: 1.5339 - val_accuracy: 0.3596\n",
      "Epoch 58/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.5258 - accuracy: 0.3618 - val_loss: 1.5289 - val_accuracy: 0.3594\n",
      "Epoch 59/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.5213 - accuracy: 0.3640 - val_loss: 1.5250 - val_accuracy: 0.3616\n",
      "Epoch 60/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.5164 - accuracy: 0.3650 - val_loss: 1.5203 - val_accuracy: 0.3662\n",
      "Epoch 61/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.5117 - accuracy: 0.3682 - val_loss: 1.5170 - val_accuracy: 0.3647\n",
      "Epoch 62/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.5076 - accuracy: 0.3706 - val_loss: 1.5128 - val_accuracy: 0.3665\n",
      "Epoch 63/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.5034 - accuracy: 0.3733 - val_loss: 1.5090 - val_accuracy: 0.3687\n",
      "Epoch 64/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.4993 - accuracy: 0.3745 - val_loss: 1.5057 - val_accuracy: 0.3717\n",
      "Epoch 65/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.4954 - accuracy: 0.3756 - val_loss: 1.5019 - val_accuracy: 0.3741\n",
      "Epoch 66/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.4912 - accuracy: 0.3790 - val_loss: 1.4985 - val_accuracy: 0.3775\n",
      "Epoch 67/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.4871 - accuracy: 0.3809 - val_loss: 1.4948 - val_accuracy: 0.3778\n",
      "Epoch 68/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.4832 - accuracy: 0.3839 - val_loss: 1.4907 - val_accuracy: 0.3791\n",
      "Epoch 69/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.4796 - accuracy: 0.3869 - val_loss: 1.4883 - val_accuracy: 0.3827\n",
      "Epoch 70/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.4761 - accuracy: 0.3883 - val_loss: 1.4853 - val_accuracy: 0.3865\n",
      "Epoch 71/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.4720 - accuracy: 0.3923 - val_loss: 1.4825 - val_accuracy: 0.3874\n",
      "Epoch 72/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.4685 - accuracy: 0.3939 - val_loss: 1.4790 - val_accuracy: 0.3905\n",
      "Epoch 73/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.4646 - accuracy: 0.3992 - val_loss: 1.4763 - val_accuracy: 0.3908\n",
      "Epoch 74/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.4608 - accuracy: 0.4006 - val_loss: 1.4738 - val_accuracy: 0.3909\n",
      "Epoch 75/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.4579 - accuracy: 0.4034 - val_loss: 1.4710 - val_accuracy: 0.4008\n",
      "Epoch 76/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.4546 - accuracy: 0.4077 - val_loss: 1.4675 - val_accuracy: 0.4020\n",
      "Epoch 77/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.4509 - accuracy: 0.4101 - val_loss: 1.4649 - val_accuracy: 0.4068\n",
      "Epoch 78/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.4475 - accuracy: 0.4144 - val_loss: 1.4618 - val_accuracy: 0.4076\n",
      "Epoch 79/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.4442 - accuracy: 0.4181 - val_loss: 1.4581 - val_accuracy: 0.4116\n",
      "Epoch 80/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.4411 - accuracy: 0.4214 - val_loss: 1.4557 - val_accuracy: 0.4176\n",
      "Epoch 81/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.4378 - accuracy: 0.4241 - val_loss: 1.4522 - val_accuracy: 0.4187\n",
      "Epoch 82/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.4341 - accuracy: 0.4263 - val_loss: 1.4498 - val_accuracy: 0.4238\n",
      "Epoch 83/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.4306 - accuracy: 0.4324 - val_loss: 1.4469 - val_accuracy: 0.4274\n",
      "Epoch 84/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 1.4266 - accuracy: 0.4374 - val_loss: 1.4433 - val_accuracy: 0.4285\n",
      "Epoch 85/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.4234 - accuracy: 0.4384 - val_loss: 1.4406 - val_accuracy: 0.4292\n",
      "Epoch 86/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.4201 - accuracy: 0.4423 - val_loss: 1.4380 - val_accuracy: 0.4351\n",
      "Epoch 87/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.4164 - accuracy: 0.4459 - val_loss: 1.4338 - val_accuracy: 0.4402\n",
      "Epoch 88/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.4132 - accuracy: 0.4498 - val_loss: 1.4311 - val_accuracy: 0.4440\n",
      "Epoch 89/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.4092 - accuracy: 0.4509 - val_loss: 1.4274 - val_accuracy: 0.4454\n",
      "Epoch 90/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.4053 - accuracy: 0.4550 - val_loss: 1.4249 - val_accuracy: 0.4494\n",
      "Epoch 91/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.4013 - accuracy: 0.4612 - val_loss: 1.4221 - val_accuracy: 0.4532\n",
      "Epoch 92/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.3979 - accuracy: 0.4619 - val_loss: 1.4173 - val_accuracy: 0.4533\n",
      "Epoch 93/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.3938 - accuracy: 0.4656 - val_loss: 1.4134 - val_accuracy: 0.4590\n",
      "Epoch 94/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.3903 - accuracy: 0.4665 - val_loss: 1.4094 - val_accuracy: 0.4600\n",
      "Epoch 95/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.3865 - accuracy: 0.4715 - val_loss: 1.4059 - val_accuracy: 0.4603\n",
      "Epoch 96/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.3824 - accuracy: 0.4717 - val_loss: 1.4027 - val_accuracy: 0.4653\n",
      "Epoch 97/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.3786 - accuracy: 0.4744 - val_loss: 1.3987 - val_accuracy: 0.4646\n",
      "Epoch 98/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.3745 - accuracy: 0.4777 - val_loss: 1.3957 - val_accuracy: 0.4682\n",
      "Epoch 99/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.3703 - accuracy: 0.4806 - val_loss: 1.3933 - val_accuracy: 0.4695\n",
      "Epoch 100/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 1.3666 - accuracy: 0.4841 - val_loss: 1.3892 - val_accuracy: 0.4710\n",
      "Val Loss: 1.3891555070877075\n",
      "Val Acc:  0.47099998593330383\n",
      "{'optimizer': <keras.optimizers.optimizer_v2.gradient_descent.SGD object at 0x7f271d995430>}\n",
      "Training...\n",
      "Epoch 1/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2839 - accuracy: 0.1309 - val_loss: 2.2599 - val_accuracy: 0.1771\n",
      "Epoch 2/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 2.1893 - accuracy: 0.2993 - val_loss: 2.0687 - val_accuracy: 0.3646\n",
      "Epoch 3/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.8815 - accuracy: 0.3941 - val_loss: 1.6990 - val_accuracy: 0.4100\n",
      "Epoch 4/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.5818 - accuracy: 0.4157 - val_loss: 1.4779 - val_accuracy: 0.4302\n",
      "Epoch 5/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.4179 - accuracy: 0.4371 - val_loss: 1.3624 - val_accuracy: 0.4471\n",
      "Epoch 6/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.3235 - accuracy: 0.4573 - val_loss: 1.2823 - val_accuracy: 0.4710\n",
      "Epoch 7/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.2580 - accuracy: 0.4778 - val_loss: 1.2359 - val_accuracy: 0.5094\n",
      "Epoch 8/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.2186 - accuracy: 0.5071 - val_loss: 1.2001 - val_accuracy: 0.5242\n",
      "Epoch 9/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.1884 - accuracy: 0.5190 - val_loss: 1.1681 - val_accuracy: 0.5486\n",
      "Epoch 10/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.1650 - accuracy: 0.5512 - val_loss: 1.1617 - val_accuracy: 0.5730\n",
      "Epoch 11/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.1407 - accuracy: 0.5597 - val_loss: 1.1354 - val_accuracy: 0.5923\n",
      "Epoch 12/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.1200 - accuracy: 0.5847 - val_loss: 1.1079 - val_accuracy: 0.5923\n",
      "Epoch 13/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.1016 - accuracy: 0.5968 - val_loss: 1.0883 - val_accuracy: 0.6231\n",
      "Epoch 14/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.0850 - accuracy: 0.6130 - val_loss: 1.0792 - val_accuracy: 0.6110\n",
      "Epoch 15/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.0672 - accuracy: 0.6209 - val_loss: 1.0567 - val_accuracy: 0.6222\n",
      "Epoch 16/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.0444 - accuracy: 0.6360 - val_loss: 1.0386 - val_accuracy: 0.6333\n",
      "Epoch 17/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.0260 - accuracy: 0.6542 - val_loss: 1.0201 - val_accuracy: 0.6805\n",
      "Epoch 18/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 1.0006 - accuracy: 0.6954 - val_loss: 0.9966 - val_accuracy: 0.7159\n",
      "Epoch 19/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.9874 - accuracy: 0.6983 - val_loss: 1.0083 - val_accuracy: 0.6956\n",
      "Epoch 20/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.9720 - accuracy: 0.7085 - val_loss: 0.9555 - val_accuracy: 0.7525\n",
      "Epoch 21/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.9442 - accuracy: 0.7385 - val_loss: 0.9439 - val_accuracy: 0.7542\n",
      "Epoch 22/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.9316 - accuracy: 0.7537 - val_loss: 0.9249 - val_accuracy: 0.7790\n",
      "Epoch 23/100\n",
      "1875/1875 [==============================] - 5s 3ms/step - loss: 0.9171 - accuracy: 0.7603 - val_loss: 0.9081 - val_accuracy: 0.7912\n",
      "Epoch 24/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.8848 - accuracy: 0.7867 - val_loss: 0.8702 - val_accuracy: 0.8079\n",
      "Epoch 25/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.8669 - accuracy: 0.7884 - val_loss: 0.8576 - val_accuracy: 0.8090\n",
      "Epoch 26/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.8511 - accuracy: 0.7993 - val_loss: 0.8512 - val_accuracy: 0.8153\n",
      "Epoch 27/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.8374 - accuracy: 0.8062 - val_loss: 0.8241 - val_accuracy: 0.8191\n",
      "Epoch 28/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.8130 - accuracy: 0.8196 - val_loss: 0.8224 - val_accuracy: 0.8201\n",
      "Epoch 29/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7980 - accuracy: 0.8201 - val_loss: 0.7988 - val_accuracy: 0.8287\n",
      "Epoch 30/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7918 - accuracy: 0.8230 - val_loss: 0.7951 - val_accuracy: 0.8302\n",
      "Epoch 31/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7824 - accuracy: 0.8243 - val_loss: 0.7767 - val_accuracy: 0.8448\n",
      "Epoch 32/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7680 - accuracy: 0.8356 - val_loss: 0.7758 - val_accuracy: 0.8374\n",
      "Epoch 33/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7541 - accuracy: 0.8378 - val_loss: 0.7633 - val_accuracy: 0.8410\n",
      "Epoch 34/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7518 - accuracy: 0.8384 - val_loss: 0.7813 - val_accuracy: 0.8311\n",
      "Epoch 35/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7489 - accuracy: 0.8287 - val_loss: 0.7602 - val_accuracy: 0.8204\n",
      "Epoch 36/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7232 - accuracy: 0.8435 - val_loss: 0.7333 - val_accuracy: 0.8470\n",
      "Epoch 37/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7125 - accuracy: 0.8499 - val_loss: 0.7251 - val_accuracy: 0.8472\n",
      "Epoch 38/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7093 - accuracy: 0.8463 - val_loss: 0.7107 - val_accuracy: 0.8518\n",
      "Epoch 39/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.7018 - accuracy: 0.8465 - val_loss: 0.7030 - val_accuracy: 0.8559\n",
      "Epoch 40/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6936 - accuracy: 0.8516 - val_loss: 0.7198 - val_accuracy: 0.8429\n",
      "Epoch 41/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6799 - accuracy: 0.8595 - val_loss: 0.6887 - val_accuracy: 0.8578\n",
      "Epoch 42/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6586 - accuracy: 0.8666 - val_loss: 0.6776 - val_accuracy: 0.8586\n",
      "Epoch 43/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6558 - accuracy: 0.8669 - val_loss: 0.6590 - val_accuracy: 0.8774\n",
      "Epoch 44/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6415 - accuracy: 0.8734 - val_loss: 0.6559 - val_accuracy: 0.8677\n",
      "Epoch 45/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6382 - accuracy: 0.8738 - val_loss: 0.6385 - val_accuracy: 0.8840\n",
      "Epoch 46/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6259 - accuracy: 0.8775 - val_loss: 0.6364 - val_accuracy: 0.8825\n",
      "Epoch 47/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6208 - accuracy: 0.8795 - val_loss: 0.6110 - val_accuracy: 0.8953\n",
      "Epoch 48/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6120 - accuracy: 0.8783 - val_loss: 0.6321 - val_accuracy: 0.8655\n",
      "Epoch 49/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6107 - accuracy: 0.8767 - val_loss: 0.6074 - val_accuracy: 0.8851\n",
      "Epoch 50/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.6017 - accuracy: 0.8821 - val_loss: 0.6205 - val_accuracy: 0.8787\n",
      "Epoch 51/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5982 - accuracy: 0.8783 - val_loss: 0.6149 - val_accuracy: 0.8749\n",
      "Epoch 52/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5946 - accuracy: 0.8768 - val_loss: 0.6074 - val_accuracy: 0.8788\n",
      "Epoch 53/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5859 - accuracy: 0.8827 - val_loss: 0.5973 - val_accuracy: 0.8838\n",
      "Epoch 54/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5890 - accuracy: 0.8826 - val_loss: 0.5969 - val_accuracy: 0.8851\n",
      "Val Loss: 0.5969477295875549\n",
      "Val Acc:  0.8851000070571899\n",
      "{'optimizer': <keras.optimizers.optimizer_v2.gradient_descent.SGD object at 0x7f271d995370>}\n",
      "Training...\n",
      "Epoch 1/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3070 - accuracy: 0.0987 - val_loss: 2.3071 - val_accuracy: 0.0980\n",
      "Epoch 2/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3065 - accuracy: 0.0987 - val_loss: 2.3065 - val_accuracy: 0.0980\n",
      "Epoch 3/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3059 - accuracy: 0.0987 - val_loss: 2.3060 - val_accuracy: 0.0980\n",
      "Epoch 4/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3054 - accuracy: 0.0987 - val_loss: 2.3055 - val_accuracy: 0.0980\n",
      "Epoch 5/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3049 - accuracy: 0.0987 - val_loss: 2.3049 - val_accuracy: 0.0980\n",
      "Epoch 6/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3044 - accuracy: 0.0987 - val_loss: 2.3044 - val_accuracy: 0.0980\n",
      "Epoch 7/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3039 - accuracy: 0.0987 - val_loss: 2.3039 - val_accuracy: 0.0980\n",
      "Epoch 8/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3034 - accuracy: 0.0987 - val_loss: 2.3035 - val_accuracy: 0.0980\n",
      "Epoch 9/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3030 - accuracy: 0.0987 - val_loss: 2.3030 - val_accuracy: 0.0980\n",
      "Epoch 10/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3025 - accuracy: 0.0987 - val_loss: 2.3025 - val_accuracy: 0.0980\n",
      "Epoch 11/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3021 - accuracy: 0.0987 - val_loss: 2.3021 - val_accuracy: 0.0980\n",
      "Epoch 12/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3016 - accuracy: 0.0988 - val_loss: 2.3017 - val_accuracy: 0.0981\n",
      "Epoch 13/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3012 - accuracy: 0.0989 - val_loss: 2.3012 - val_accuracy: 0.0985\n",
      "Epoch 14/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3008 - accuracy: 0.0996 - val_loss: 2.3008 - val_accuracy: 0.0998\n",
      "Epoch 15/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3004 - accuracy: 0.1019 - val_loss: 2.3004 - val_accuracy: 0.1029\n",
      "Epoch 16/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.3000 - accuracy: 0.1055 - val_loss: 2.3000 - val_accuracy: 0.1095\n",
      "Epoch 17/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2997 - accuracy: 0.1128 - val_loss: 2.2996 - val_accuracy: 0.1171\n",
      "Epoch 18/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2993 - accuracy: 0.1214 - val_loss: 2.2993 - val_accuracy: 0.1290\n",
      "Epoch 19/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2989 - accuracy: 0.1328 - val_loss: 2.2989 - val_accuracy: 0.1394\n",
      "Epoch 20/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2986 - accuracy: 0.1452 - val_loss: 2.2985 - val_accuracy: 0.1515\n",
      "Epoch 21/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2982 - accuracy: 0.1566 - val_loss: 2.2982 - val_accuracy: 0.1654\n",
      "Epoch 22/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2979 - accuracy: 0.1677 - val_loss: 2.2978 - val_accuracy: 0.1745\n",
      "Epoch 23/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2975 - accuracy: 0.1777 - val_loss: 2.2975 - val_accuracy: 0.1835\n",
      "Epoch 24/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2972 - accuracy: 0.1853 - val_loss: 2.2972 - val_accuracy: 0.1900\n",
      "Epoch 25/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2969 - accuracy: 0.1913 - val_loss: 2.2968 - val_accuracy: 0.1938\n",
      "Epoch 26/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2966 - accuracy: 0.1948 - val_loss: 2.2965 - val_accuracy: 0.1977\n",
      "Epoch 27/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2962 - accuracy: 0.1966 - val_loss: 2.2962 - val_accuracy: 0.1981\n",
      "Epoch 28/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2959 - accuracy: 0.1968 - val_loss: 2.2958 - val_accuracy: 0.1983\n",
      "Epoch 29/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2956 - accuracy: 0.1953 - val_loss: 2.2955 - val_accuracy: 0.1971\n",
      "Epoch 30/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2953 - accuracy: 0.1936 - val_loss: 2.2952 - val_accuracy: 0.1960\n",
      "Epoch 31/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2950 - accuracy: 0.1918 - val_loss: 2.2949 - val_accuracy: 0.1934\n",
      "Epoch 32/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2947 - accuracy: 0.1895 - val_loss: 2.2946 - val_accuracy: 0.1910\n",
      "Epoch 33/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2944 - accuracy: 0.1873 - val_loss: 2.2943 - val_accuracy: 0.1878\n",
      "Epoch 34/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 2.2941 - accuracy: 0.1847 - val_loss: 2.2939 - val_accuracy: 0.1855\n",
      "Epoch 35/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2938 - accuracy: 0.1819 - val_loss: 2.2936 - val_accuracy: 0.1823\n",
      "Epoch 36/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2935 - accuracy: 0.1795 - val_loss: 2.2933 - val_accuracy: 0.1795\n",
      "Epoch 37/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2932 - accuracy: 0.1764 - val_loss: 2.2930 - val_accuracy: 0.1778\n",
      "Epoch 38/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2929 - accuracy: 0.1736 - val_loss: 2.2927 - val_accuracy: 0.1756\n",
      "Epoch 39/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2926 - accuracy: 0.1710 - val_loss: 2.2924 - val_accuracy: 0.1729\n",
      "Epoch 40/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2923 - accuracy: 0.1690 - val_loss: 2.2921 - val_accuracy: 0.1704\n",
      "Epoch 41/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2920 - accuracy: 0.1666 - val_loss: 2.2918 - val_accuracy: 0.1681\n",
      "Epoch 42/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2917 - accuracy: 0.1650 - val_loss: 2.2915 - val_accuracy: 0.1659\n",
      "Epoch 43/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2914 - accuracy: 0.1624 - val_loss: 2.2912 - val_accuracy: 0.1633\n",
      "Epoch 44/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2911 - accuracy: 0.1606 - val_loss: 2.2909 - val_accuracy: 0.1626\n",
      "Epoch 45/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2908 - accuracy: 0.1598 - val_loss: 2.2906 - val_accuracy: 0.1611\n",
      "Epoch 46/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2905 - accuracy: 0.1578 - val_loss: 2.2903 - val_accuracy: 0.1593\n",
      "Epoch 47/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2902 - accuracy: 0.1566 - val_loss: 2.2900 - val_accuracy: 0.1583\n",
      "Epoch 48/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2899 - accuracy: 0.1562 - val_loss: 2.2896 - val_accuracy: 0.1574\n",
      "Epoch 49/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2896 - accuracy: 0.1549 - val_loss: 2.2893 - val_accuracy: 0.1562\n",
      "Epoch 50/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2893 - accuracy: 0.1550 - val_loss: 2.2890 - val_accuracy: 0.1553\n",
      "Epoch 51/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2890 - accuracy: 0.1533 - val_loss: 2.2887 - val_accuracy: 0.1551\n",
      "Epoch 52/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2887 - accuracy: 0.1531 - val_loss: 2.2884 - val_accuracy: 0.1536\n",
      "Epoch 53/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2884 - accuracy: 0.1518 - val_loss: 2.2881 - val_accuracy: 0.1536\n",
      "Epoch 54/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2881 - accuracy: 0.1519 - val_loss: 2.2878 - val_accuracy: 0.1532\n",
      "Epoch 55/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2878 - accuracy: 0.1512 - val_loss: 2.2874 - val_accuracy: 0.1528\n",
      "Epoch 56/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2875 - accuracy: 0.1515 - val_loss: 2.2871 - val_accuracy: 0.1521\n",
      "Epoch 57/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2871 - accuracy: 0.1517 - val_loss: 2.2868 - val_accuracy: 0.1528\n",
      "Epoch 58/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2868 - accuracy: 0.1514 - val_loss: 2.2865 - val_accuracy: 0.1527\n",
      "Epoch 59/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2865 - accuracy: 0.1519 - val_loss: 2.2861 - val_accuracy: 0.1529\n",
      "Epoch 60/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2861 - accuracy: 0.1519 - val_loss: 2.2858 - val_accuracy: 0.1530\n",
      "Epoch 61/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2858 - accuracy: 0.1529 - val_loss: 2.2854 - val_accuracy: 0.1533\n",
      "Epoch 62/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2855 - accuracy: 0.1527 - val_loss: 2.2851 - val_accuracy: 0.1539\n",
      "Epoch 63/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2851 - accuracy: 0.1531 - val_loss: 2.2847 - val_accuracy: 0.1546\n",
      "Epoch 64/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2848 - accuracy: 0.1543 - val_loss: 2.2844 - val_accuracy: 0.1558\n",
      "Epoch 65/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2844 - accuracy: 0.1551 - val_loss: 2.2840 - val_accuracy: 0.1566\n",
      "Epoch 66/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2841 - accuracy: 0.1560 - val_loss: 2.2836 - val_accuracy: 0.1579\n",
      "Epoch 67/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2837 - accuracy: 0.1572 - val_loss: 2.2832 - val_accuracy: 0.1586\n",
      "Epoch 68/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2833 - accuracy: 0.1581 - val_loss: 2.2829 - val_accuracy: 0.1600\n",
      "Epoch 69/100\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 2.2830 - accuracy: 0.1598 - val_loss: 2.2825 - val_accuracy: 0.1617\n",
      "Epoch 70/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2826 - accuracy: 0.1612 - val_loss: 2.2821 - val_accuracy: 0.1635\n",
      "Epoch 71/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2822 - accuracy: 0.1628 - val_loss: 2.2817 - val_accuracy: 0.1655\n",
      "Epoch 72/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2818 - accuracy: 0.1649 - val_loss: 2.2813 - val_accuracy: 0.1673\n",
      "Epoch 73/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2814 - accuracy: 0.1670 - val_loss: 2.2809 - val_accuracy: 0.1697\n",
      "Epoch 74/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2810 - accuracy: 0.1685 - val_loss: 2.2804 - val_accuracy: 0.1718\n",
      "Epoch 75/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2806 - accuracy: 0.1713 - val_loss: 2.2800 - val_accuracy: 0.1740\n",
      "Epoch 76/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2801 - accuracy: 0.1739 - val_loss: 2.2796 - val_accuracy: 0.1767\n",
      "Epoch 77/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2797 - accuracy: 0.1768 - val_loss: 2.2791 - val_accuracy: 0.1801\n",
      "Epoch 78/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2792 - accuracy: 0.1799 - val_loss: 2.2786 - val_accuracy: 0.1839\n",
      "Epoch 79/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2788 - accuracy: 0.1832 - val_loss: 2.2782 - val_accuracy: 0.1891\n",
      "Epoch 80/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2783 - accuracy: 0.1865 - val_loss: 2.2777 - val_accuracy: 0.1921\n",
      "Epoch 81/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2778 - accuracy: 0.1908 - val_loss: 2.2772 - val_accuracy: 0.1955\n",
      "Epoch 82/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2773 - accuracy: 0.1948 - val_loss: 2.2767 - val_accuracy: 0.1996\n",
      "Epoch 83/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2768 - accuracy: 0.1983 - val_loss: 2.2762 - val_accuracy: 0.2044\n",
      "Epoch 84/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2763 - accuracy: 0.2034 - val_loss: 2.2756 - val_accuracy: 0.2088\n",
      "Epoch 85/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2757 - accuracy: 0.2079 - val_loss: 2.2751 - val_accuracy: 0.2133\n",
      "Epoch 86/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2752 - accuracy: 0.2120 - val_loss: 2.2745 - val_accuracy: 0.2186\n",
      "Epoch 87/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2746 - accuracy: 0.2162 - val_loss: 2.2739 - val_accuracy: 0.2222\n",
      "Epoch 88/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2740 - accuracy: 0.2206 - val_loss: 2.2733 - val_accuracy: 0.2272\n",
      "Epoch 89/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2734 - accuracy: 0.2236 - val_loss: 2.2727 - val_accuracy: 0.2324\n",
      "Epoch 90/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2728 - accuracy: 0.2281 - val_loss: 2.2721 - val_accuracy: 0.2359\n",
      "Epoch 91/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2722 - accuracy: 0.2323 - val_loss: 2.2714 - val_accuracy: 0.2387\n",
      "Epoch 92/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2715 - accuracy: 0.2363 - val_loss: 2.2707 - val_accuracy: 0.2420\n",
      "Epoch 93/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2708 - accuracy: 0.2401 - val_loss: 2.2700 - val_accuracy: 0.2455\n",
      "Epoch 94/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2701 - accuracy: 0.2447 - val_loss: 2.2693 - val_accuracy: 0.2488\n",
      "Epoch 95/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2694 - accuracy: 0.2486 - val_loss: 2.2686 - val_accuracy: 0.2532\n",
      "Epoch 96/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2687 - accuracy: 0.2529 - val_loss: 2.2678 - val_accuracy: 0.2565\n",
      "Epoch 97/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2679 - accuracy: 0.2564 - val_loss: 2.2670 - val_accuracy: 0.2599\n",
      "Epoch 98/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2671 - accuracy: 0.2594 - val_loss: 2.2662 - val_accuracy: 0.2628\n",
      "Epoch 99/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2663 - accuracy: 0.2632 - val_loss: 2.2654 - val_accuracy: 0.2656\n",
      "Epoch 100/100\n",
      "1875/1875 [==============================] - 6s 3ms/step - loss: 2.2654 - accuracy: 0.2665 - val_loss: 2.2645 - val_accuracy: 0.2684\n",
      "Val Loss: 2.2645151615142822\n",
      "Val Acc:  0.26840001344680786\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "def make_model(optimizer):\n",
    "  model = keras.models.Sequential()\n",
    "  model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "\n",
    "  model.add(keras.layers.Dense(50, activation='sigmoid'))\n",
    "  model.add(keras.layers.Dense(10, activation='sigmoid'))\n",
    "\n",
    "  model.add(keras.layers.Dense(len(np.unique(y_train)), activation='softmax'))\n",
    "\n",
    "  model.add(keras.layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "\n",
    "  model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=optimizer,\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "  return model\n",
    "\n",
    "cls = KerasClassifier(build_fn=make_model)\n",
    "\n",
    "SGD_lr = {\n",
    "    tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    "    tf.keras.optimizers.SGD(learning_rate=0.001),\n",
    "    tf.keras.optimizers.SGD(learning_rate=0.0001)\n",
    "}\n",
    "\n",
    "param_grid = {'optimizer' : SGD_lr}\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=1)\n",
    "\n",
    "results = list()\n",
    "for params in ParameterGrid(param_grid=param_grid):\n",
    "  cls.set_params(**params)\n",
    "\n",
    "  print(params)\n",
    "\n",
    "  print('Training...')\n",
    "  history = cls.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test), callbacks=[callback])\n",
    "\n",
    "  df = pd.DataFrame(history.history)\n",
    "\n",
    "  print('Val Loss:', history.history['val_loss'][-1])\n",
    "  print('Val Acc: ', history.history['val_accuracy'][-1])\n",
    "\n",
    "\n",
    "  results.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n_H4nGcyY-l-"
   },
   "source": [
    "**Try searching for the optimal learning rate.**\n",
    "\n",
    "I used grid search method to search SGD learning rates: 0.01, 0.001, and 0.0001. The best accuracy resulted from the learning rate of 0.001, which I believe is the default learning rate."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
